<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>

 Tensor
</title>
<link href="doctorch.css" rel="stylesheet" type="text/css">
</head>

<body class="torchdoc">
<div id="container">

<div id="header">
<h3>
 Tensor</h3>
</div>

<div id="navline">
<a href="../index.html">Torch Manual</a>&nbsp; > &nbsp; <a href="index.html">
Torch Package Reference Manual</a>&nbsp; > &nbsp; <b>
 <code>Tensor</code></b>
</div>

<div id="contents">
<a name="Tensor"></a>

<p>

<p>

The <code>Tensor</code> class is probably the most important class in <code>Torch</code>. Almost every package depends on this
class. It is <b>the</b> class for handling numeric data. Tensors are <a href="index-2-4.html#FileSerialization">serializable</a>.
<p>

<b>Multi-dimensional matrix</b>
<p>

A <code>Tensor</code> is a potentially multi-dimensional matrix. The number of
dimensions is unlimited. Many methods have some convenience methods for for
a number of dimensions inferior or equal to <code>4</code>, but can also be used using
<a href="index-5.html#Storage"><code>LongStorage</code></a> with more dimensions. Example:
<pre>
 --- creation of a 4D-tensor 4x5x6x2
 z = torch.Tensor(4,5,6,2)
 --- for more dimensions, (here a 6D tensor) one can do:
 s = torch.LongStorage(6)
 s[1] = 4; s[2] = 5; s[3] = 6; s[4] = 2; s[5] = 7; s[6] = 3;
 x = torch.Tensor(s)
</pre>
<p>

The number of dimensions of a <code>Tensor</code> can be queried by
<a href="index-6-2-1.html#TensorNDimension"><code>nDimension()</code></a> or <a href="index-6-2-2.html#TensorDim"><code>dim()</code></a>. Size of
the <code>i-th</code> dimension is returned by <a href="index-6-2-3.html#TensorSizeDim"><code>size(i)</code></a>. An
<a href="index-5.html#Storage"><code>LongStorage</code></a> containing all the dimensions can be returned by
<a href="index-6-2-4.html#TensorSize"><code>size()</code></a>.
<pre>
> print(x:nDimension())
6
> print(x:size())
 4
 5
 6
 2
 7
 3
[torch.LongStorage of size 6]
</pre>
<p>

<b>Internal data representation</b>
<p>

The actual data of a <code>Tensor</code> is contained into a
<a href="index-5.html#Storage"><code>DoubleStorage</code></a>. It can be accessed using
<a href="index-6-2-8.html#TensorStorage"><code>storage()</code></a>. While the memory of a <code>Tensor</code> has to be
contained in this unique <code>Storage</code>, it might not be contiguous:
the first position used in the <code>Storage</code> is given by <code>storageOffset()</code>
(starting at <code>1</code>). And the <i>jump</i> needed to go from one element to another element
in the <code>i-th</code> dimension is given by <code>stride(i)</code>. In other words, given a 3D tensor
<pre>
x = torch.Tensor(7,7,7)
</pre>
accessing the element <code>(3,4,5)</code> can be done by
<pre>
= x[3][4][5]
</pre>
or equivalently (but slowly!)
<pre>
= x:storage()[x:storageOffset()
           +(3-1)*x:stride(1)+(4-1)*x:stride(2)+(5-1)*x:stride(3)]
</pre>
One could say that a <code>Tensor</code> is a particular way of <i>viewing</i> a
<code>Storage</code>: a <code>Storage</code> only represents a chunk of memory, while the
<code>Tensor</code> interprets this chunk of memory as having dimensions:
<pre>
> x = torch.Tensor(4,5)
> s = x:storage()
> for i=1,s:size() do -- fill up the Storage
>> s[i] = i
>> end
> print(x) -- s is interpreted by x as a 2D matrix

  1   5   9  13  17
  2   6  10  14  18
  3   7  11  15  19
  4   8  12  16  20
[torch.Tensor of dimension 4x5]
</pre>
<p>

Note also that in <code>Torch</code> <i>elements in the same column</i> [elements along the first dimension]
are contiguous in memory for a matrix [tensor]:
<pre>
> x = torch.Tensor(4,5):zero()
> print(x)

0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
[torch.Tensor of dimension 4x5]

> return  x:stride()
 1 -- element in the first dimension are contiguous!
 4
[torch.LongStorage of size 2]
</pre>
This is like in Fortran (and not <code>C</code>), which allows us to efficiently
interface <code>Torch</code> with standard numerical library packages.
<p>

<b>Tensors of different types</b>
<p>

Actually, several types of <code>Tensor</code> exists:
<pre>
CharTensor -- contains chars
ShortTensor -- contains shorts
IntTensor -- contains ints
FloatTensor -- contains floats
Tensor -- contains doubles
</pre>
<p>

It is recommended using only <code>Tensor</code>, as many of the numeric operations
are not implemented for other classes.  However, in some cases, you might
want to use another class, e.g. to save memory space.
<p>

<b>Efficient memory managment</b>
<p>

<i>All</i> tensor operations in this class do <i>not</i> make any memory copy. All
these methods transform the existing tensor, or return a new tensor
referencing <i>the same storage</i>. This magical behavior is internally
obtained by good usage of the <a href="index-6-2-7.html#TensorStride"><code>stride()</code></a> and
<a href="index-6-2-12.html#TensorStorageOffset"><code>storageOffset()</code></a>. Example:
<pre>
> x = torch.Tensor(5):zero()
> print(x)
0
0
0
0
0
[torch.Tensor of dimension 5]
> x:narrow(1, 2, 3):fill(1) -- narrow() returns a Tensor
                            -- referencing the same Storage than x
> print(x)
 0
 1
 1
 1
 0
[torch.Tensor of dimension 5]
</pre>
<p>

If you really need to copy a <code>Tensor</code>, you can use the <a href="index-6-5-1.html#TensorCopy"><code>copy()</code></a> method:
<pre>
> y = torch.Tensor():resizeAs(x):copy(x)
</pre>
<p>

We now describe all the methods for <code>Tensor</code>, but for the other variants,
just replace <code>Tensor</code> by the name of the variant (like <code>CharTensor</code>).
<p>

<p>

</div>

<div id="subsections">
<h3>Subsections</h3>
<ol>
<li><a href="index-6-1.html">
 Tensor constructors</a></li>
<li><a href="index-6-2.html">
 Querying the size and structure</a></li>
<li><a href="index-6-3.html">
 Querying elements</a></li>
<li><a href="index-6-4.html">
 Referencing a tensor to an existing tensor or chunk of memory</a></li>
<li><a href="index-6-5.html">
 Copying and initializing</a></li>
<li><a href="index-6-6.html">
 Resizing</a></li>
<li><a href="index-6-7.html">
 Extracting sub-tensors</a></li>
<li><a href="index-6-8.html">
 Manipulating the tensor view</a></li>
<li><a href="index-6-9.html">
 Applying a function to a tensor</a></li>
<li><a href="index-6-10.html">
 Math functions</a></li>
<li><a href="index-6-11.html">
 Basic statistics</a></li>
<li><a href="index-6-12.html">
 Basic operations</a></li>
<li><a href="index-6-13.html">
 Overloaded operators</a></li>
</ol>

</div>

<div id="footer-left">&nbsp;<a href="index-5.html">
 <code>Storage</code> and <code>MapStorage</code></a></div>
<div id="footer-right"><a href="index-7.html">
 <code>Timer</code></a>&nbsp;</div>

<div id="last-modified">

</div>

</div>
</body>
</html>
