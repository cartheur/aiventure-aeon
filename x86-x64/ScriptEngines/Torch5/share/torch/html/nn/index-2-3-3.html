<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>

 Add 
</title>
<link href="doctorch.css" rel="stylesheet" type="text/css">
</head>

<body class="torchdoc">
<div id="container">

<div id="header">
<h3>
 Add </h3>
</div>

<div id="navline">
<a href="../index.html">Torch Manual</a>&nbsp; > &nbsp; <a href="index.html">
Neural Network Package</a>&nbsp; > &nbsp; <a href="index-2.html">
 Modules</a>&nbsp; > &nbsp; <a href="index-2-3.html">
 Simple layers</a>&nbsp; > &nbsp; <b>
 <code>Add</code> </b>
</div>

<div id="contents">
<a name="Add"></a>

<p>

<p>

<code>module</code> = <code>Add(inputDimension,scalar)</code>
<p>

Applies a bias term to the incoming data, i.e.
_y_i= x_i + b_i,  or if <i>scalar=true</i> then uses a single bias term,
_y_i= x_i + b. 
<p>

Example:
<pre>
y=torch.Tensor(5);  
mlp=nn.Sequential()
mlp:add(nn.Add(5))

function gradUpdate(mlp, x, y, criterion, learningRate) 
  local pred = mlp:forward(x)
  local err = criterion:forward(pred, y)
  local gradCriterion = criterion:backward(pred, y)
  mlp:zeroGradParameters()
  mlp:backward(x, gradCriterion)
  mlp:updateParameters(learningRate)
  return err
end

for i=1,10000 do
 x=lab.rand(5)
 y:copy(x); 
 for i=1,5 do y[i]=y[i]+i; end
 err=gradUpdate(mlp,x,y,nn.MSECriterion(),0.01)
end
print(mlp:get(1).bias)
</pre>
gives the output:
<pre>
 1.0000
 2.0000
 3.0000
 4.0000
 5.0000
[torch.Tensor of dimension 5]
</pre>
i.e. the network successfully learns the input <i>x</i> has been shifted 
to produce the output <i>y</i>.
<p>

<p>

</div>



<div id="footer-left">&nbsp;<a href="index-2-3-2.html">
 <code>SparseLinear</code></a></div>
<div id="footer-right"><a href="index-2-3-4.html">
 <code>Mul</code></a>&nbsp;</div>

<div id="last-modified">

</div>

</div>
</body>
</html>
