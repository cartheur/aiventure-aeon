<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>

 TemporalSubSampling
</title>
<link href="doctorch.css" rel="stylesheet" type="text/css">
</head>

<body class="torchdoc">
<div id="container">

<div id="header">
<h3>
 TemporalSubSampling</h3>
</div>

<div id="navline">
<a href="../index.html">Torch Manual</a>&nbsp; > &nbsp; <a href="index.html">
Neural Network Package</a>&nbsp; > &nbsp; <a href="index-2.html">
 Modules</a>&nbsp; > &nbsp; <a href="index-2-5.html">
 Convolutional layers</a>&nbsp; > &nbsp; <b>
 <code>TemporalSubSampling</code></b>
</div>

<div id="contents">

<p>

<pre>
module = nn.TemporalSubSampling(inputFrameSize, kW, [dW])
</pre>
<p>

Applies a 1D sub-sampling over an input sequence composed of <code>nInputFrame</code> frames. The <code>input</code> tensor in
<code>forward(input)</code> is expected to be a 2D tensor (<code>inputFrameSize x nInputFrame</code>). The output frame size
will be the same as the input one (<code>inputFrameSize</code>).
<p>

The parameters are the following:
<dl><dt> <code>inputFrameSize</code></dt><dd>The input frame size expected in sequences given into <code>forward()</code>.
</dd><dt> <code>kW</code></dt><dd>The kernel width of the sub-sampling
</dd><dt> <code>dW</code></dt><dd>The step of the sub-sampling. Default is <code>1</code>.
</dd></dl><p>

Note that depending of the size of your kernel, several (of the last)
frames of the sequence might be lost. It is up to the user to add proper padding frames in the input
sequences.
<p>

If the input sequence is a 2D tensor <code>inputFrameSize x nInputFrame</code>, the output sequence will be
<code>inputFrameSize x nOutputFrame</code> where
<pre>
nOutputFrame = (nInputFrame - kW) / dW + 1
</pre>
<p>

The parameters of the sub-sampling can be found in <code>self.weight</code> (Tensor of
size <code>inputFrameSize</code>) and <code>self.bias</code> (Tensor of
size <code>inputFrameSize</code>). The corresponding gradients can be found in
<code>self.gradWeight</code> and <code>self.gradBias</code>.
<p>

The output value of the layer can be precisely described as:
<pre>
output[i][t] = bias[i] + weight[i] * sum_{k=1}^kW input[i][dW*(t-1)+k)]
</pre>
<p>

</div>



<div id="footer-left">&nbsp;<a href="index-2-5-3.html">
 <code>TemporalConvolution</code></a></div>
<div id="footer-right"><a href="index-2-5-5.html">
 <code>LookupTable</code></a>&nbsp;</div>

<div id="last-modified">

</div>

</div>
</body>
</html>
