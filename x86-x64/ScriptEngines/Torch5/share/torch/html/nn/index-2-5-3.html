<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>

 TemporalConvolution
</title>
<link href="doctorch.css" rel="stylesheet" type="text/css">
</head>

<body class="torchdoc">
<div id="container">

<div id="header">
<h3>
 TemporalConvolution</h3>
</div>

<div id="navline">
<a href="../index.html">Torch Manual</a>&nbsp; > &nbsp; <a href="index.html">
Neural Network Package</a>&nbsp; > &nbsp; <a href="index-2.html">
 Modules</a>&nbsp; > &nbsp; <a href="index-2-5.html">
 Convolutional layers</a>&nbsp; > &nbsp; <b>
 <code>TemporalConvolution</code></b>
</div>

<div id="contents">

<p>

<pre>
module = nn.TemporalConvolution(inputFrameSize, outputFrameSize, kW, [dW])
</pre>
<p>

Applies a 1D convolution over an input sequence composed of <code>nInputFrame</code> frames. The <code>input</code> tensor in
<code>forward(input)</code> is expected to be a 2D tensor (<code>inputFrameSize x nInputFrame</code>).
<p>

The parameters are the following:
<dl><dt> <code>inputFrameSize</code></dt><dd>The input frame size expected in sequences given into <code>forward()</code>.
</dd><dt> <code>outputFrameSize</code></dt><dd>The output frame size the convolution layer will produce.
</dd><dt> <code>kW</code></dt><dd>The kernel width of the convolution
</dd><dt> <code>dW</code></dt><dd>The step of the convolution. Default is <code>1</code>.
</dd></dl><p>

Note that depending of the size of your kernel, several (of the last)
frames of the sequence might be lost. It is up to the user to add proper padding frames in the input
sequences.
<p>

If the input sequence is a 2D tensor <code>inputFrameSize x nInputFrame</code>, the output sequence will be
<code>outputFrameSize x nOutputFrame</code> where
<pre>
nOutputFrame = (nInputFrame - kW) / dW + 1
</pre>
<p>

The parameters of the convolution can be found in <code>self.weight</code> (Tensor of
size <code>inputFrameSize x kW x outputFrameSize</code>) and <code>self.bias</code> (Tensor of
size <code>outputFrameSize</code>). The corresponding gradients can be found in
<code>self.gradWeight</code> and <code>self.gradBias</code>.
<p>

The output value of the layer can be precisely described as:
<pre>
output[i][t] = bias[i]
  + sum_j sum_{k=1}^kW weight[j][k][i]
                                * input[j][dW*(t-1)+k)]
</pre>
<p>

Here is a simple example:
<p>

<pre>
inp=5;  -- dimensionality of one sequence element 
outp=1; -- number of derived features for one sequence element
kw=1;   -- kernel only operates on one sequence element at once
dw=1;   -- we step once and go on to the next sequence element

mlp=nn.TemporalConvolution(inp,outp,kw,dw)

require "lab"
x=lab.rand(inp,7) -- a sequence of 7 elements
print(mlp:forward(x))
</pre>
which gives:
<pre>
-0.9109 -0.9872 -0.6808 -0.9403 -0.9680 -0.6901 -0.6387
[torch.Tensor of dimension 1x7]
</pre>
<p>

This is equivalent to:
<pre>
weights=lab.reshape(mlp.weight,inp) -- weights applied to all
bias= mlp.bias[1];
for i=1,x:size(2) do -- for each sequence element
 element= x:t()[i]; -- features of ith sequence element
 print(element:dot(weights) + bias)
end
</pre>
which gives:
<pre>
-0.91094998687717
-0.98721705771773
-0.68075004276185
-0.94030132495887
-0.96798754116609
-0.69008470895581
-0.63871422284166
</pre>
<p>

<p>

</div>



<div id="footer-left">&nbsp;<a href="index-2-5-2.html">
 <code>SpatialSubSampling</code></a></div>
<div id="footer-right"><a href="index-2-5-4.html">
 <code>TemporalSubSampling</code></a>&nbsp;</div>

<div id="last-modified">

</div>

</div>
</body>
</html>
