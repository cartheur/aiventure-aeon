<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>

 Linear
</title>
<link href="doctorch.css" rel="stylesheet" type="text/css">
</head>

<body class="torchdoc">
<div id="container">

<div id="header">
<h3>
 Linear</h3>
</div>

<div id="navline">
<a href="../index.html">Torch Manual</a>&nbsp; > &nbsp; <a href="index.html">
Neural Network Package</a>&nbsp; > &nbsp; <a href="index-2.html">
 Modules</a>&nbsp; > &nbsp; <a href="index-2-3.html">
 Simple layers</a>&nbsp; > &nbsp; <b>
 <code>Linear</code></b>
</div>

<div id="contents">
<a name="Linear"></a>

<p>

<p>

<code>module</code> = <code>Linear(inputDimension,outputDimension)</code>
<p>

Applies a linear transformation to the incoming data, i.e.
<i>y= Ax+b</i>. The <code>input</code> tensor given in <code>forward(input)</code> must
be a vector (1D tensor).
<p>

You can create a layer in the following way:
<pre>
 module= nn.Linear(10,5)  -- 10 inputs, 5 outputs
</pre>
Usually this would be added to a network of some kind, e.g.:
<pre>
 mlp = nn.Sequential();
 mlp:add(module)
</pre>
The weights and biases (<i>A</i> and <i>b</i>) can be viewed with:
<pre>
 print(module.weight)
 print(module.bias)
</pre>
The gradients for these weights can be seen with:
<pre>
 print(module.gradWeight)
 print(module.gradBias)
</pre>
As usual with <code>nn</code> modules,
 applying the linear transformation is performed with:
<pre>
 x=torch.Tensor(10) -- 10 inputs
 y=module:forward(x)
</pre>
<p>

</div>



<div id="footer-left">&nbsp;<a href=""></a></div>
<div id="footer-right"><a href="index-2-3-2.html">
 <code>SparseLinear</code></a>&nbsp;</div>

<div id="last-modified">

</div>

</div>
</body>
</html>
